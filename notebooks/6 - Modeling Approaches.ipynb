{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd074886-2170-4969-ba3c-657e41a47963",
   "metadata": {},
   "source": [
    "# Modeling Approaches and Considerations\n",
    "\n",
    "Now that we've gone through the extensive process of finding, exploring, annotating, and curating our datasets - we're ready to start the modeling process.\n",
    "\n",
    "In this notebook, we're going to go through three main approaches:\n",
    "1. Rule-based approach\n",
    "2. Machine learning approach\n",
    "3. GenAI: RAG Approach\n",
    "\n",
    "<br/>\n",
    "\n",
    "In each case, we will levereage the best practices discussed in the book, including:\n",
    "- Consistent training and testing sets\n",
    "- Testing performance multiple ways (e.g. sentence vs document level)\n",
    "- Out of sample testing to demonstrate generalizability\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9431bb56-dd71-470b-9218-f0c3b551a49f",
   "metadata": {},
   "source": [
    "First, let's load packages and the data we need from previous notbooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e16d3e79-bd4e-45c7-a13e-cb507990dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachelwagner-kaiser/.pyenv/versions/tc2r_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.stats import ks_2samp\n",
    "import umap.umap_ as umap\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import annoy\n",
    "from annoy import AnnoyIndex\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6814b226-3b58-43a2-ad77-4ba78e975680",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HOME_DIRECTORY = os.getenv(\"HOME_DIRECTORY\")\n",
    "\n",
    "sent_emb_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cebb1bb-6e14-4c38-9263-e3a90378ed67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tm2421105d1_ex10-1.htm</td>\n",
       "      <td>Payment of invoices submitted for Services wil...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tm2022502d7_ex10-1.htm</td>\n",
       "      <td>Except as the applicable Provider and Recipien...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d203747dex1015.html</td>\n",
       "      <td>6.3 Unless otherwise agreed in writing by\\nthe...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pinstripesdistributionag.html</td>\n",
       "      <td>The Customer agrees to pay such invoices withi...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spar ex99-1.htm</td>\n",
       "      <td>● All\\n                                       ...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Filename  \\\n",
       "0         tm2421105d1_ex10-1.htm   \n",
       "1         tm2022502d7_ex10-1.htm   \n",
       "2            d203747dex1015.html   \n",
       "3  pinstripesdistributionag.html   \n",
       "4                spar ex99-1.htm   \n",
       "\n",
       "                                                Text Answer  \n",
       "0  Payment of invoices submitted for Services wil...     30  \n",
       "1  Except as the applicable Provider and Recipien...     30  \n",
       "2  6.3 Unless otherwise agreed in writing by\\nthe...     30  \n",
       "3  The Customer agrees to pay such invoices withi...     30  \n",
       "4  ● All\\n                                       ...     30  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load Payment terms annotations\n",
    "payment_annos_all = pd.read_excel(os.path.join(HOME_DIRECTORY, 'data', 'annotations', 'Payment_semantic_search-annotated.xlsx'), engine='openpyxl')\n",
    "\n",
    "### Convert to embeddings\n",
    "payment_annos_all['Embedding'] = payment_annos_all['Text'].apply(lambda t: sent_emb_model.encode(t))\n",
    "\n",
    "### Remove false positives\n",
    "payment_annos = payment_annos_all[payment_annos_all['Answer']!='FALSE POSITIVE']\n",
    "\n",
    "### Check\n",
    "payment_annos[['Filename', 'Text', 'Answer']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e3aaeb-b9d9-4efa-aaae-ea9c6a99ce2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v5/zjyjffl52010h549863n0ggm0000gn/T/ipykernel_15220/2043368028.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  sentence_embeddings['Label'].loc[(sentence_embeddings['filename'].isin(payment_annos['Filename'])) & (\n",
      "/var/folders/v5/zjyjffl52010h549863n0ggm0000gn/T/ipykernel_15220/2043368028.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_embeddings['Label'].loc[(sentence_embeddings['filename'].isin(payment_annos['Filename'])) & (\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings = pd.read_pickle(os.path.join(HOME_DIRECTORY, 'data', 'data_pickles', 'corpus_sentences_embedded.pkl'))\n",
    "sentence_embeddings.reset_index(inplace=True)\n",
    "sentence_embeddings.drop('index', axis=1, inplace=True)\n",
    "\n",
    "sentence_embeddings['Label'] = 0*len(sentence_embeddings)\n",
    "\n",
    "sentence_embeddings['Label'].loc[(sentence_embeddings['filename'].isin(payment_annos['Filename'])) & (\n",
    "        sentence_embeddings.index.isin(payment_annos['Index']))] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd40ec0-11fd-41f3-941c-3092696b5d2b",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Let's sanity check to make sure our labels are set up correctly -- first the positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d4bdffe-bcb8-445e-8731-6c6dd5455d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>{BEAB7EBB-320F-40B6-A8EC-46FA106E041A}.pdf.txt</td>\n",
       "      <td>381</td>\n",
       "      <td>The City will process\\npayment within 60 days ...</td>\n",
       "      <td>[-0.16759498, -0.27937645, 0.01358771, -0.3186...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046</th>\n",
       "      <td>{37D87A51-8A39-4C71-A95E-39039D4F8035}.pdf.txt</td>\n",
       "      <td>2685</td>\n",
       "      <td>Payment willbe processed within 60 days ater t...</td>\n",
       "      <td>[0.038814455, -0.17314807, -0.3497632, -0.2625...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6454</th>\n",
       "      <td>00000JZM.pdf.txt</td>\n",
       "      <td>308</td>\n",
       "      <td>The City wil\\nprocess the payment within 60 ca...</td>\n",
       "      <td>[0.25620103, 0.11852089, -0.233818, -0.2146448...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20328</th>\n",
       "      <td>000023CH.pdf.txt</td>\n",
       "      <td>273</td>\n",
       "      <td>The City will process payment within 60 days a...</td>\n",
       "      <td>[-0.047622316, -0.079943694, 0.051177025, -0.2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31327</th>\n",
       "      <td>00001Q81.pdf.txt</td>\n",
       "      <td>1059</td>\n",
       "      <td>The Depariment wil process propery completed i...</td>\n",
       "      <td>[-0.1272221, -0.02062763, -0.11731366, -0.2323...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename  sentence_index  \\\n",
       "498    {BEAB7EBB-320F-40B6-A8EC-46FA106E041A}.pdf.txt             381   \n",
       "5046   {37D87A51-8A39-4C71-A95E-39039D4F8035}.pdf.txt            2685   \n",
       "6454                                 00000JZM.pdf.txt             308   \n",
       "20328                                000023CH.pdf.txt             273   \n",
       "31327                                00001Q81.pdf.txt            1059   \n",
       "\n",
       "                                           sentence_text  \\\n",
       "498    The City will process\\npayment within 60 days ...   \n",
       "5046   Payment willbe processed within 60 days ater t...   \n",
       "6454   The City wil\\nprocess the payment within 60 ca...   \n",
       "20328  The City will process payment within 60 days a...   \n",
       "31327  The Depariment wil process propery completed i...   \n",
       "\n",
       "                                               Embedding  Label  \n",
       "498    [-0.16759498, -0.27937645, 0.01358771, -0.3186...      1  \n",
       "5046   [0.038814455, -0.17314807, -0.3497632, -0.2625...      1  \n",
       "6454   [0.25620103, 0.11852089, -0.233818, -0.2146448...      1  \n",
       "20328  [-0.047622316, -0.079943694, 0.051177025, -0.2...      1  \n",
       "31327  [-0.1272221, -0.02062763, -0.11731366, -0.2323...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings[sentence_embeddings.index.isin(payment_annos['Index'])].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a455211a-55e6-4487-ac1c-faf49dd86379",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Let's double check the negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3912ab5-4531-456f-b1dc-1807c7a5237c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002MGK.pdf.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>Modification Summary Report\\n\\n</td>\n",
       "      <td>[-0.41111374, 0.21261811, 0.20041092, -0.20724...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002MGK.pdf.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Conteact (PO) Number: 1406\\nModification Revis...</td>\n",
       "      <td>[-0.5395347, 0.098074794, 0.105878145, -0.1364...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002MGK.pdf.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>Specification Number: 3858\\n\\n</td>\n",
       "      <td>[-1.0228841, 0.4157112, -0.75348186, -0.048902...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002MGK.pdf.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>Name of Contractor: GLOBETROTTERS ENGINEERING ...</td>\n",
       "      <td>[-0.38846922, -0.24451904, -0.4939656, -0.3636...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00002MGK.pdf.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>City Department: DEPARTMENT OF CONSTRUCTION AN...</td>\n",
       "      <td>[0.008176829, -0.01078279, -0.06635815, -0.172...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename  sentence_index  \\\n",
       "0  00002MGK.pdf.txt               0   \n",
       "1  00002MGK.pdf.txt               1   \n",
       "2  00002MGK.pdf.txt               2   \n",
       "3  00002MGK.pdf.txt               3   \n",
       "4  00002MGK.pdf.txt               4   \n",
       "\n",
       "                                       sentence_text  \\\n",
       "0                    Modification Summary Report\\n\\n   \n",
       "1  Conteact (PO) Number: 1406\\nModification Revis...   \n",
       "2                     Specification Number: 3858\\n\\n   \n",
       "3  Name of Contractor: GLOBETROTTERS ENGINEERING ...   \n",
       "4  City Department: DEPARTMENT OF CONSTRUCTION AN...   \n",
       "\n",
       "                                           Embedding  Label  \n",
       "0  [-0.41111374, 0.21261811, 0.20041092, -0.20724...      0  \n",
       "1  [-0.5395347, 0.098074794, 0.105878145, -0.1364...      0  \n",
       "2  [-1.0228841, 0.4157112, -0.75348186, -0.048902...      0  \n",
       "3  [-0.38846922, -0.24451904, -0.4939656, -0.3636...      0  \n",
       "4  [0.008176829, -0.01078279, -0.06635815, -0.172...      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings[~sentence_embeddings.index.isin(payment_annos['Index'])].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6c348-9295-4f79-b78f-63dd6ff6a4a2",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "# 0. Define Train and Test Sets\n",
    "\n",
    "Regardless of what approach we are using for modeling, we need to have a consistent training set and testing set. This will enable us to compare apples to apples across the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9cbbfca-6c08-469c-9a43-9884033ee530",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "test_files = random.sample(list(payment_annos['Filename'].values), \n",
    "                          round(0.2*len(payment_annos)))\n",
    "train_files = [i for i in payment_annos['Filename'].values if i not in test_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a5b665-7270-4a7d-b1fd-cf7aa876ebbd",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Sanity check to confirm everything adds up:\n",
    "1. total length of annotations == test + train lengths\n",
    "2. no intersection / overlap between train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "679b4b95-3d8e-4ce5-baee-3b3027dac9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 234, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_files), len(train_files), len(test_files)+len(train_files)==len(payment_annos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6f1d9e-c01d-4015-b4fe-3b896c28b6ae",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Now let's add flags to our annotation dataframe for which positive annotations are in the test set vs the train set - we will add another column to track this information as we use it throughout our different modeling approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1ba1aa0-009d-4184-b053-d6fb4aa8de25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v5/zjyjffl52010h549863n0ggm0000gn/T/ipykernel_15220/1334593889.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  payment_annos['Dataset'] = ['Test' if ann in test_files else 'Train' for ann in payment_annos['Filename'].values]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Index</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Text</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tm2421105d1_ex10-1.htm</td>\n",
       "      <td>796139</td>\n",
       "      <td>0.826294</td>\n",
       "      <td>Payment of invoices submitted for Services wil...</td>\n",
       "      <td>[-0.116843455, -0.263676, -0.07310186, -0.4452...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tm2022502d7_ex10-1.htm</td>\n",
       "      <td>817242</td>\n",
       "      <td>0.813836</td>\n",
       "      <td>Except as the applicable Provider and Recipien...</td>\n",
       "      <td>[-0.050476346, 0.053603664, -0.1944099, -0.068...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d203747dex1015.html</td>\n",
       "      <td>902124</td>\n",
       "      <td>0.801718</td>\n",
       "      <td>6.3 Unless otherwise agreed in writing by\\nthe...</td>\n",
       "      <td>[0.10877621, 0.02559486, -0.09234318, -0.09299...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pinstripesdistributionag.html</td>\n",
       "      <td>856859</td>\n",
       "      <td>0.799900</td>\n",
       "      <td>The Customer agrees to pay such invoices withi...</td>\n",
       "      <td>[-0.067744344, -0.07578232, -0.23484993, -0.35...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spar ex99-1.htm</td>\n",
       "      <td>876506</td>\n",
       "      <td>0.797764</td>\n",
       "      <td>● All\\n                                       ...</td>\n",
       "      <td>[-0.17738403, -0.064912006, 0.049998302, -0.23...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Filename   Index  Cosine Similarity  \\\n",
       "0         tm2421105d1_ex10-1.htm  796139           0.826294   \n",
       "1         tm2022502d7_ex10-1.htm  817242           0.813836   \n",
       "2            d203747dex1015.html  902124           0.801718   \n",
       "3  pinstripesdistributionag.html  856859           0.799900   \n",
       "4                spar ex99-1.htm  876506           0.797764   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Payment of invoices submitted for Services wil...   \n",
       "1  Except as the applicable Provider and Recipien...   \n",
       "2  6.3 Unless otherwise agreed in writing by\\nthe...   \n",
       "3  The Customer agrees to pay such invoices withi...   \n",
       "4  ● All\\n                                       ...   \n",
       "\n",
       "                                           Embedding Answer Comment Dataset  \n",
       "0  [-0.116843455, -0.263676, -0.07310186, -0.4452...     30     NaN   Train  \n",
       "1  [-0.050476346, 0.053603664, -0.1944099, -0.068...     30     NaN    Test  \n",
       "2  [0.10877621, 0.02559486, -0.09234318, -0.09299...     30     NaN   Train  \n",
       "3  [-0.067744344, -0.07578232, -0.23484993, -0.35...     30     NaN    Test  \n",
       "4  [-0.17738403, -0.064912006, 0.049998302, -0.23...     30     NaN   Train  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_annos['Dataset'] = ['Test' if ann in test_files else 'Train' for ann in payment_annos['Filename'].values]\n",
    "payment_annos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262a066a-e53a-4f8a-9e62-a071433ef3ae",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Now let's do a double check of our train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d27e360b-5b68-4646-972a-69cc407047fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset\n",
       "Train    234\n",
       "Test      58\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_annos['Dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4617a057-1854-40d8-aca0-30a5f54e8e8b",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "We also need to apply this to our general population so that we can also test the negative examples as well as the positive ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b18cab49-9e01-405a-adc2-d8595995beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings['Dataset'] = ['Train']*len(sentence_embeddings)\n",
    "test_inds = sentence_embeddings.sample(frac=0.2, random_state=12345).index\n",
    "sentence_embeddings.loc[test_inds, 'Dataset'] = 'Test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c49f20d-be1c-4bc7-99e8-9ea3d7599f54",
   "metadata": {},
   "source": [
    "And let's do another sanity check to confirm our split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95e4cc23-2837-4e76-841b-c883c78d17a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset\n",
       "Train    774359\n",
       "Test     193590\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings['Dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed89b2d1-7b2f-4003-9199-1b68ae645dd2",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "# 1. Rule-Driven Approach\n",
    "\n",
    "With a rule-driven, deterministic approach, we typically create a handful of business rules to capture the common patterns we see in the language of our annations. However, we very quickly need to balance this by checking how many false positives we will get from these same rules across the other sentences in the corpus.\n",
    "\n",
    "Most who are familiar with leveraging regular expressions to find and extract information out of a corpus know that it is almost an art form to create a rule that is precise enough to find the language that we are looking for, without being overly surgical in a way that makes it too brittle and prone to fail when new language is run through the regular expressions.\n",
    "\n",
    "First, let's write a couple quick rules -- which we can write quickly based on our experience with the annotations. The best practice is to use a train set (for rule development and iteration) and test set (for rule test) split to develop the regex. In this case, we will develop with a train-test split on our annotations, and additionally test on an out of sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e022d24-0653-443c-858a-f92900ff0bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_search(text):\n",
    "    if re.search('(payment[\\w\\W]{,30}days|days[\\w\\W]{,30}payment)', text, re.IGNORECASE):\n",
    "        return True\n",
    "    elif re.search('(pay\\s[\\w\\W]{,30}\\d\\d[\\w\\W]{,10}day|\\d\\d[\\w\\W]{,10}day[\\w\\W]{,30}pay\\s)', text, re.IGNORECASE):\n",
    "        return True\n",
    "    elif re.search('((pay|paid)\\s[\\w\\W]{,150}\\d\\d[\\w\\W]{,10}day|\\d\\d[\\w\\W]{,10}invoice)', text, re.IGNORECASE):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0be42-7d0e-415c-95d4-f918f4341783",
   "metadata": {},
   "source": [
    "<br/>\n",
    "We can quickly run this over our annotations and see that it's fairly effective on our train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e244250a-f969-4bad-bd5b-8f15072e6481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def assess_rules(payment_annos, dataset):\n",
    "    print('Percent Annotations Captured by rules:', \n",
    "      round(sum(payment_annos[payment_annos['Dataset']==dataset]['Text'].apply(\n",
    "          lambda x: rule_search(x)))/len(payment_annos[payment_annos['Dataset']==dataset])*100,2))\n",
    "    return payment_annos[payment_annos['Dataset']==dataset]['Text'].apply(lambda x: rule_search(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "257a77a4-aa0f-4352-ad51-1bf7721fd0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Annotations Captured by rules: 63.68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "2       True\n",
       "4       True\n",
       "6      False\n",
       "7       True\n",
       "       ...  \n",
       "338     True\n",
       "339     True\n",
       "342     True\n",
       "345    False\n",
       "347    False\n",
       "Name: Text, Length: 234, dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assess_rules(payment_annos, 'Train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e574803e-9016-49ea-9b76-b0001d199246",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Great news - it took all of 3 minutes and we now have a rule that captures about 65% of our annotations correctly. For some use cases, that might be entirely sufficient, and if so, then this is the approach for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2bbd33-493b-4c0f-ba2b-59d0307c0f0a",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.1:\n",
    "\n",
    "Update and add regex rules to improve precision and recall on the training set.\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c004aa80-7516-4d01-96db-d24cd821eedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87982ac-4e0c-44f7-a83e-645e80b0af47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "604bb483-6182-40ec-8976-886e13d619b3",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Once we've done some iterations and are satisfied with the train performance, we can assess against our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bfc4487-7b46-4969-a665-fcbd8bc83941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Annotations Captured by rules: 68.97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1      False\n",
       "3       True\n",
       "5       True\n",
       "12     False\n",
       "13     False\n",
       "20      True\n",
       "21      True\n",
       "39      True\n",
       "46     False\n",
       "50     False\n",
       "54      True\n",
       "61     False\n",
       "63      True\n",
       "66     False\n",
       "75      True\n",
       "84      True\n",
       "85      True\n",
       "88      True\n",
       "92      True\n",
       "94      True\n",
       "96     False\n",
       "98      True\n",
       "100    False\n",
       "102     True\n",
       "110    False\n",
       "115     True\n",
       "123     True\n",
       "124    False\n",
       "138     True\n",
       "140     True\n",
       "146     True\n",
       "156     True\n",
       "162     True\n",
       "175    False\n",
       "179     True\n",
       "184     True\n",
       "185     True\n",
       "193     True\n",
       "200    False\n",
       "203    False\n",
       "204     True\n",
       "232    False\n",
       "233    False\n",
       "234    False\n",
       "246    False\n",
       "248     True\n",
       "250     True\n",
       "262     True\n",
       "293     True\n",
       "298     True\n",
       "301     True\n",
       "305     True\n",
       "308     True\n",
       "312     True\n",
       "334     True\n",
       "337     True\n",
       "340     True\n",
       "343     True\n",
       "Name: Text, dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assess_rules(payment_annos, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a637ea64-cff5-4c69-8dc9-c06ed1138562",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "But, before we celebrate too much, let's see how many false positives we get across the same annotated documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52631f9b-b6bc-4ea4-8a79-2fe14c7deeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings['Rule_Results'] = sentence_embeddings['sentence_text'].apply(lambda x: rule_search(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1890d391-87c6-47d3-bdd0-706e98dbdbaa",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Below, we count up how many \"True\" predictions that our rule captures and calculate some of our usual, basic metrics. To do this, we're going to look at the documents we annotated, and see how many sentences in those documents trigger our regular expression rules, and out of those sentences, which were annotated (true positives) and which were not (false positives).\n",
    "\n",
    "Then we can calculate our usual metrics from there..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9e3aa69-56e0-4195-8535-3afb7d6d03c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fn_tps(dataset, payment_annos):\n",
    "    rule_results = {\n",
    "        'True Positives': sum(dataset[(dataset['filename'].isin(payment_annos['Filename'])) & (dataset.index.isin(payment_annos['Index']))]['Rule_Results']),\n",
    "        'False Negatives': len(dataset[(dataset['filename'].isin(payment_annos['Filename'])) & (dataset.index.isin(payment_annos['Index']))]['Rule_Results'])-sum(dataset[(dataset.index.isin(payment_annos['Index']))]['Rule_Results']),\n",
    "        'True Negatives': len(dataset[(dataset['filename'].isin(payment_annos['Filename'])) & ~dataset.index.isin(payment_annos['Index'])]['Rule_Results'])- sum(dataset[~dataset.index.isin(payment_annos['Index'])]['Rule_Results']),\n",
    "        'False Positives': sum(dataset[(dataset['filename'].isin(payment_annos['Filename'])) & ~dataset.index.isin(payment_annos['Index'])]['Rule_Results'])}\n",
    "\n",
    "    return rule_results\n",
    "\n",
    "def calculate_metrics(dataset, payment_annos):\n",
    "    res_dict = get_fn_tps(dataset, payment_annos)\n",
    "    metrics = {\n",
    "        'Accuracy': round((res_dict['True Positives']+res_dict['True Negatives'])/(res_dict['True Positives']+res_dict['True Negatives']+res_dict['False Positives']+res_dict['False Negatives']), 4),\n",
    "        'Precision': round(res_dict['True Positives']/(res_dict['True Positives']+res_dict['False Positives']), 4),\n",
    "        'Recall': round(res_dict['True Positives']/(res_dict['True Positives']+res_dict['False Negatives']), 4),\n",
    "    }\n",
    "    return res_dict, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a76b467b-3380-43f8-90ba-1275f938091f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'True Positives': 149,\n",
       "  'False Negatives': 87,\n",
       "  'True Negatives': 217112,\n",
       "  'False Positives': 298},\n",
       " {'Accuracy': 0.9982, 'Precision': 0.3333, 'Recall': 0.6314})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(sentence_embeddings[sentence_embeddings['Dataset']=='Train'], payment_annos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69851f4e-8eba-4760-a98f-d30884b98689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'True Positives': 40,\n",
       "  'False Negatives': 16,\n",
       "  'True Negatives': 54320,\n",
       "  'False Positives': 82},\n",
       " {'Accuracy': 0.9982, 'Precision': 0.3279, 'Recall': 0.7143})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(sentence_embeddings[sentence_embeddings['Dataset']=='Test'], payment_annos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a553a7e-4475-4663-901a-a9be98172306",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "... and as we can see, although we are capturing most of our true examples, we are unfortunately going to have quite a large number of false positives compared to our true positives. And, this is only the first step of finding and extracting the right context, and doesn't even include the interpretation and standardization step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6cf07c-2230-4edb-8d2c-980af5bd5187",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.2:\n",
    "\n",
    "The metrics are currently being calculated at the sentence level. Write code to calculate the performance metrics of this approach at the *document* level, and apply to both the training and testing sets.\n",
    "\n",
    "Consider these questions as you build the code for document level performance metrics:\n",
    "- Will you consider a document correct if the regex picks up the true positive as well as additional false positives (e.g. is it correct if 1 of 3 are correct)?\n",
    "- Will you pick the first hit in the document and see if it is correct?\n",
    "- Will you build additional custom heuristics in ordering your regex rules in order of specificity?\n",
    "\n",
    "Working with rules can be highly effective when there is consistent data - but can be a challenge to scale and manage effectively.\n",
    "\n",
    "*Note that per best practices, we would typically look at both the sentence and document level training metrics as we iterate during development. Then, when ready, we would look at the sentence and document level metrics for the test set. The order is adjusted here for the sake of exercises.*\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88440fd5-6fc2-45f9-b2d9-15a19f8ab8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9441fdd1-2442-4091-a8cd-cfbc38a4090f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5813a4c-eace-494e-8ffd-1b5eb8cfbc71",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### **Rules**: Out of Sample Testing\n",
    "\n",
    "Now, let's test how well these simple rules perform on a totally new set of data -- the data we are using for our out of sample validation testing comes from the CUAD dataset, and has been labeled in the same way as our original training dataset.\n",
    "\n",
    "As we've discussed in the book, out of sample testing is a strong indication of how models will generalize and perform on new data. Let's load in the data and annotations - these have been processed the same way as our dataset and have the same dataframe format, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fa55a46-64de-4bd3-9443-e034e3633895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Index</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Text</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MERCATAINC_03_09_2000-EX-10.21-SPONSORSHIP AGR...</td>\n",
       "      <td>75171</td>\n",
       "      <td>0.818270</td>\n",
       "      <td>Invoices are         payable thirty (30) days ...</td>\n",
       "      <td>[ 2.73382105e-02  2.43578479e-01  1.58090532e-...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LiquidmetalTechnologiesInc_20200205_8-K_EX-10....</td>\n",
       "      <td>125364</td>\n",
       "      <td>0.794762</td>\n",
       "      <td>Payment terms are net 30 days after the date o...</td>\n",
       "      <td>[ 5.75190336e-02  1.15242578e-01  1.55434303e-...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEALTHGATEDATACORP_11_24_1999-EX-10.1-HOSTING ...</td>\n",
       "      <td>29071</td>\n",
       "      <td>0.781155</td>\n",
       "      <td>Invoices are payable within 60 days of receipt...</td>\n",
       "      <td>[-3.42358910e-02  2.09649265e-01  1.19534194e-...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BNCMORTGAGEINC_05_17_1999-EX-10.4-LICENSING AN...</td>\n",
       "      <td>9927</td>\n",
       "      <td>0.777679</td>\n",
       "      <td>Invoices will be paid within 15 days of receipt.</td>\n",
       "      <td>[ 1.30046410e-02  2.48915225e-01  1.91053916e-...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FuseMedicalInc_20190321_10-K_EX-10.43_11575454...</td>\n",
       "      <td>17614</td>\n",
       "      <td>0.775361</td>\n",
       "      <td>5.3 The Distributor must pay the full amount i...</td>\n",
       "      <td>[ 2.23518938e-01 -2.30259091e-01 -4.44820106e-...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename   Index  \\\n",
       "0  MERCATAINC_03_09_2000-EX-10.21-SPONSORSHIP AGR...   75171   \n",
       "1  LiquidmetalTechnologiesInc_20200205_8-K_EX-10....  125364   \n",
       "2  HEALTHGATEDATACORP_11_24_1999-EX-10.1-HOSTING ...   29071   \n",
       "3  BNCMORTGAGEINC_05_17_1999-EX-10.4-LICENSING AN...    9927   \n",
       "4  FuseMedicalInc_20190321_10-K_EX-10.43_11575454...   17614   \n",
       "\n",
       "   Cosine Similarity                                               Text  \\\n",
       "0           0.818270  Invoices are         payable thirty (30) days ...   \n",
       "1           0.794762  Payment terms are net 30 days after the date o...   \n",
       "2           0.781155  Invoices are payable within 60 days of receipt...   \n",
       "3           0.777679   Invoices will be paid within 15 days of receipt.   \n",
       "4           0.775361  5.3 The Distributor must pay the full amount i...   \n",
       "\n",
       "                                           Embedding  Answer  \n",
       "0  [ 2.73382105e-02  2.43578479e-01  1.58090532e-...      30  \n",
       "1  [ 5.75190336e-02  1.15242578e-01  1.55434303e-...      30  \n",
       "2  [-3.42358910e-02  2.09649265e-01  1.19534194e-...      60  \n",
       "3  [ 1.30046410e-02  2.48915225e-01  1.91053916e-...      15  \n",
       "4  [ 2.23518938e-01 -2.30259091e-01 -4.44820106e-...      45  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OOS_annos = pd.read_excel(os.path.join(HOME_DIRECTORY, 'data', 'annotations', 'Payment_OOS_CUAD-annotated.xlsx'), engine='openpyxl')\n",
    "OOS_annos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b7f2dc-f2da-413c-8447-9de4b70d7ae4",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "As an exercise, the user can create the embedded pickle for the out-of-sample CUAD data. The pickle loaded below is also available via the Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7e94abc-ccfa-411c-b443-828eae337257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v5/zjyjffl52010h549863n0ggm0000gn/T/ipykernel_15220/1467854628.py:4: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  OOS_sentences['Label'].loc[(OOS_sentences['filename'].isin(OOS_annos['Filename'])) & (\n",
      "/var/folders/v5/zjyjffl52010h549863n0ggm0000gn/T/ipykernel_15220/1467854628.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  OOS_sentences['Label'].loc[(OOS_sentences['filename'].isin(OOS_annos['Filename'])) & (\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGRE...</td>\n",
       "      <td>0</td>\n",
       "      <td>EXHIBIT 10.6\\n\\n                              ...</td>\n",
       "      <td>[-0.10622965, -0.44307116, -0.17057964, 0.1905...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGRE...</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\n                                    RECITA...</td>\n",
       "      <td>[0.026612738, -0.21556377, -0.27186835, -0.283...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGRE...</td>\n",
       "      <td>2</td>\n",
       "      <td>The Company is  presently  engaged in the bus...</td>\n",
       "      <td>[-0.4307863, -0.012101413, -0.10511014, 0.2095...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGRE...</td>\n",
       "      <td>3</td>\n",
       "      <td>The Company may engage in the business of sel...</td>\n",
       "      <td>[-0.12590498, -0.45511994, -0.26844802, -0.373...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGRE...</td>\n",
       "      <td>4</td>\n",
       "      <td>\\n\\n         B. Representations.</td>\n",
       "      <td>[-0.23541977, 0.1468132, -0.5211692, 0.0794706...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  sentence_index  \\\n",
       "0  LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGRE...               0   \n",
       "1  LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGRE...               1   \n",
       "2  LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGRE...               2   \n",
       "3  LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGRE...               3   \n",
       "4  LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGRE...               4   \n",
       "\n",
       "                                       sentence_text  \\\n",
       "0  EXHIBIT 10.6\\n\\n                              ...   \n",
       "1  \\n\\n                                    RECITA...   \n",
       "2   The Company is  presently  engaged in the bus...   \n",
       "3   The Company may engage in the business of sel...   \n",
       "4                   \\n\\n         B. Representations.   \n",
       "\n",
       "                                           Embedding  Label  \n",
       "0  [-0.10622965, -0.44307116, -0.17057964, 0.1905...      0  \n",
       "1  [0.026612738, -0.21556377, -0.27186835, -0.283...      0  \n",
       "2  [-0.4307863, -0.012101413, -0.10511014, 0.2095...      0  \n",
       "3  [-0.12590498, -0.45511994, -0.26844802, -0.373...      0  \n",
       "4  [-0.23541977, 0.1468132, -0.5211692, 0.0794706...      0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OOS_sentences = pd.read_pickle(os.path.join(HOME_DIRECTORY, 'data', 'data_pickles', 'OOS_CUAD_sentences_embedded.pkl'))\n",
    "\n",
    "OOS_sentences['Label'] = 0*len(OOS_sentences)\n",
    "OOS_sentences['Label'].loc[(OOS_sentences['filename'].isin(OOS_annos['Filename'])) & (\n",
    "        OOS_sentences.index.isin(OOS_annos['Index']))] = 1\n",
    "\n",
    "OOS_sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1773a79d-95b1-4bc4-891d-66a3f2282c32",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "Let's do a quick comparison of our original dataset compared to our CUAD out of sample dataset - we'll compare the overall corpus distribution by visualizing the embeddings in the same space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "384b65de-4033-463f-8792-e0406dec217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison_corpora(sentence_embeddings1, sentence_embeddings2, embedding_col, sample_size=None):\n",
    "    if sample_size is None:\n",
    "        sentence_embeddings_sample1 = sentence_embeddings1\n",
    "        sentence_embeddings_sample2 = sentence_embeddings2\n",
    "    else:\n",
    "        sentence_embeddings_sample1 = sentence_embeddings1.sample(sample_size, random_state=100)\n",
    "        sentence_embeddings_sample2 = sentence_embeddings2.sample(sample_size, random_state=100)\n",
    "\n",
    "    reducer = umap.UMAP(n_neighbors=20, random_state=1)\n",
    "    umap_embeds = reducer.fit_transform(np.array([np.array(x) for x in pd.concat((\n",
    "        sentence_embeddings_sample1[embedding_col],sentence_embeddings_sample2[embedding_col])) ]))\n",
    "    plt.scatter(umap_embeds[:sample_size,0], umap_embeds[:sample_size,1], alpha=0.3, color='royalblue', s=3, label='CUAD Sample')\n",
    "    plt.scatter(umap_embeds[sample_size:,0], umap_embeds[sample_size:,1], alpha=0.3, color='plum', s=3, label='Annotations')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Umap Dimension 1'); plt.ylabel('Umap Dimension 2')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63a6e5f9-aba2-4c6c-9bd3-56977f23f609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachelwagner-kaiser/.pyenv/versions/tc2r_env/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_comparison_corpora(OOS_sentences, sentence_embeddings, 'Embedding', sample_size=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bfee97-80e4-4082-8711-67b0e40b4c9a",
   "metadata": {},
   "source": [
    "<br/>\n",
    "Now, let's look at how well the rules work on our OOS dataset:\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c162936e-584a-4e0f-ae9a-83c18659c0dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Annotations Captured by rules: 47.37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1      True\n",
       "2     False\n",
       "3      True\n",
       "4      True\n",
       "      ...  \n",
       "71    False\n",
       "72     True\n",
       "73     True\n",
       "74     True\n",
       "75     True\n",
       "Name: Text, Length: 76, dtype: bool"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Percent Annotations Captured by rules:', round(sum(OOS_annos['Text'].apply(lambda x: rule_search(x)))/len(OOS_annos)*100,2))\n",
    "OOS_annos['Text'].apply(lambda x: rule_search(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "253a8236-56da-4d5a-8718-4567e1975f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOS_sentences['Rule_Results'] = OOS_sentences['sentence_text'].apply(lambda x: rule_search(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04c1f759-3f18-421b-adde-6f39a600edd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'True Positives': 34,\n",
       "  'False Negatives': 42,\n",
       "  'True Negatives': 26966,\n",
       "  'False Positives': 69},\n",
       " {'Accuracy': 0.9959, 'Precision': 0.3301, 'Recall': 0.4474})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(OOS_sentences, OOS_annos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b904e2a4-5b45-4c41-bbc5-747017d4bcee",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "As may have been expected, our regular expression based rules do not extrapolate as well with new data outside of our original population. While accuracy is still high due to the large amount of true negatives, precision is still very low and recall has dropped about 15%.\n",
    "\n",
    "Regular expressions work well for highly consistent data, but in many cases won't work nearly as well when there is variability in the corpus.\n",
    "\n",
    "Given the results of our rule-based approach so far, we have a few options now. We could to spend time refining our rules to make them more specific and to improve performance. Or -- we can try a machine learning approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2efd02-ccc2-4b50-b95c-3c4e2501fe31",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.3:\n",
    "\n",
    "But first - one additional exercise. Leveraging your function from before, calculate the performance metrics at the document level for the out of sample documents.\n",
    "\n",
    "How do these metrics compare to the in-sample metrics?\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d841903f-2937-4278-92a5-f056a59d6789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883475d-9a96-4004-92d1-edcecc6f5998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fb87330-49a5-48c9-87a0-2bb394b6abad",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "# 2. Machine Learning Approach\n",
    "\n",
    "Now, let's take a more probabalistic approach by leveraging machine learning to better identify the right sentence in the document that discusses payment terms. We will start by building a sentence-level classifier with our sentence embeddings. \n",
    "\n",
    "With this approach, we can also limit false positives by selecting only the top probability sentence to per document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fab29a0d-7437-4320-8f74-ca51a774f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_annotated_files = sentence_embeddings[sentence_embeddings['filename'].isin(payment_annos['Filename'])]\n",
    "ml_neg_sample = ml_annotated_files[ml_annotated_files['Label']==0].sample(n=5000, random_state=1)\n",
    "ml_pos_sample = ml_annotated_files[ml_annotated_files['Label']==1]\n",
    "ml_sample = pd.concat((ml_neg_sample, ml_pos_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f1289-740d-4155-bfd4-62d95332983d",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Now, what we've done above to create our sample is:\n",
    "- Limit to our annotated documents\n",
    "- Taken several thousand random samples of negative sentences\n",
    "- Added our known positive annotated sentences\n",
    "\n",
    "Why are we not doing additional selection of our sample? For instance, we could do further filtering to keep only sentences of a certain length, throwing out likely non-sensical / non-sentence examples like clause headings or junk like \"Contract (PO) Number: 26568\\n\\n‘\". Or, we could filter to only keep high quality OCR sentences, with a high percentage of words that are in the dictionary.\n",
    "\n",
    "However, what would be the impact of this filtering on our model training process? If the model doesn't see these types of low-quality OCR or irrelevant, short sentences, it won't learn that these are negative examples of what we are looking for. It is valuable to leave these types of examples in the mix of our negative examples, since it will represent the range of what we will see \"in the wild\" when we are using these models at scale.\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30d43731-d172-434d-9dcd-b9db340b34b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for x in ml_sample[ml_sample['Dataset']=='Train']['Embedding'].values:\n",
    "    X_train.append(x)\n",
    "\n",
    "X_test = []\n",
    "for x in ml_sample[ml_sample['Dataset']=='Test']['Embedding'].values:\n",
    "    X_test.append(x)\n",
    "\n",
    "y_train = ml_sample[ml_sample['Dataset']=='Train']['Label'].values\n",
    "y_test = ml_sample[ml_sample['Dataset']=='Test']['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6b34a87-61ba-4f4a-853f-e55553955717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4172, 384), (1120, 384), (4172,), (1120,)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.shape(a) for a in [X_train, X_test, y_train, y_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e852f65-8cd7-49fd-acc9-711d964686c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=150, random_state=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "112235d5-c02b-4278-8cf5-2cd22000aff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3936    0]\n",
      " [   0  236]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3936\n",
      "           1       1.00      1.00      1.00       236\n",
      "\n",
      "    accuracy                           1.00      4172\n",
      "   macro avg       1.00      1.00      1.00      4172\n",
      "weighted avg       1.00      1.00      1.00      4172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e38d2601-2457-4ac4-bd17-006cddd88a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1062    2]\n",
      " [   6   50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1064\n",
      "           1       0.96      0.89      0.93        56\n",
      "\n",
      "    accuracy                           0.99      1120\n",
      "   macro avg       0.98      0.95      0.96      1120\n",
      "weighted avg       0.99      0.99      0.99      1120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6bfc5223-0160-49a2-983c-6b363ad10609",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = os.path.join(HOME_DIRECTORY, 'data', 'models')\n",
    "model_name = 'ml_classifier_gbc.pkl'\n",
    "\n",
    "with open(os.path.join(model_save_path, model_name), 'wb') as file:\n",
    "        pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5675c-6c4d-44b9-9644-f8c38407fed2",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Now, we've built and tested a reasonably good model to retrieve the relevant sentences for payment terms. But, let's go one step further here and check the probabilities to see how strong the separation is between positive and negative examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "409be287-ddaa-4ee8-b4ef-37a7e10bcba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_thresholds = pd.DataFrame([y_train, clf.predict_proba(X_train)[:,1]]).T\n",
    "train_thresholds.columns = ['Label', 'Pred Probability']\n",
    "test_thresholds = pd.DataFrame([y_test, clf.predict_proba(X_test)[:,1]]).T\n",
    "test_thresholds.columns = train_thresholds.columns\n",
    "\n",
    "plt.hist(train_thresholds[train_thresholds['Label']==0]['Pred Probability'], color='royalblue', alpha=0.75, bins=np.arange(0,1.1,.1), density=True);\n",
    "plt.hist(train_thresholds[train_thresholds['Label']==1]['Pred Probability'], color='plum', alpha=0.75, bins=np.arange(0,1.1,.1), density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "daa3290b-28c6-4284-b27b-062986ceb0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_thresholds[test_thresholds['Label']==0]['Pred Probability'], color='royalblue', alpha=0.75, bins=np.arange(0,1.1,.1), density=True);\n",
    "plt.hist(test_thresholds[test_thresholds['Label']==1]['Pred Probability'], color='plum', alpha=0.75, bins=np.arange(0,1.1,.1), density=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f5b647-4db3-437c-90d8-33c6147f8c52",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.4:\n",
    "\n",
    "Explore using TF-IDF instead of embeddings as features. How do the sentence and document level metrics change? Why might this happen?\n",
    "\n",
    "*(TF-IDF tips: remember to limit vocab size to avoid overfitting, use a small range of n-grams, and ignore very low and very high probability tokens)*\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bac736-6ad4-4bb6-876f-f31c88b95a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51429951-1966-45f5-9926-829486366c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "683f1517-8ae9-42ab-8e1d-18cf36cf259c",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.5:\n",
    "\n",
    "Try an alternative supervised classification algorithm. Is there a statistically significant difference?\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a289a4b3-0d7c-46bc-8fe8-857c6e67b48f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f648c2-d135-4012-a7c8-c9bb35a647f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b191180-9e77-4e95-b8e1-66256efbc896",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.6:\n",
    "\n",
    "Test changing the threshold for model predictions from the default of 0.5. How does this impact performance on the train and the test sets?\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f186a4bb-8e44-45f7-9789-9e66b79514d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a44186b-5bbb-466a-bed7-56f61de115e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "467ea779-b90d-4c4c-82b8-d5c61939b1ef",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### **Machine Learning**: Document-Level Testing\n",
    "\n",
    "Now, we have built a model to identify the context in the document discussing payment terms. However, we have only tested the performance on a sentence-by-sentence level. Now we need to evaluate if we can maintain a high level performance at a *document* level, where we are extracting the top probability sentence from each document.\n",
    "\n",
    "We'll start by predicting the probability for each individual sentence, then pick the top per each document and compare to the real, annotated answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2be94cb6-ce19-41f4-bd55-20507f31abb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v5/zjyjffl52010h549863n0ggm0000gn/T/ipykernel_15220/269179956.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ml_annotated_files['Probability'] = ml_annotated_files['Embedding'].apply(lambda x: clf.predict_proba([x])[0][1]);\n",
      "/var/folders/v5/zjyjffl52010h549863n0ggm0000gn/T/ipykernel_15220/269179956.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ml_annotated_files['Predicted Label'] = ml_annotated_files['Probability'].apply(lambda x: 0 if x<threshold else 1);\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "ml_annotated_files['Probability'] = ml_annotated_files['Embedding'].apply(lambda x: clf.predict_proba([x])[0][1]);\n",
    "ml_annotated_files['Predicted Label'] = ml_annotated_files['Probability'].apply(lambda x: 0 if x<threshold else 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1a728db-0df2-45c7-970d-0bbf99ee4327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Label</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Rule_Results</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6454</th>\n",
       "      <td>00000JZM.pdf.txt</td>\n",
       "      <td>308</td>\n",
       "      <td>The City wil\\nprocess the payment within 60 ca...</td>\n",
       "      <td>[0.25620103, 0.11852089, -0.233818, -0.2146448...</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>True</td>\n",
       "      <td>0.998688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69340</th>\n",
       "      <td>00000LRJ.pdf.txt</td>\n",
       "      <td>294</td>\n",
       "      <td>The City will process payment within 60 days a...</td>\n",
       "      <td>[-0.12235852, -0.09604282, 0.036402386, -0.198...</td>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445210</th>\n",
       "      <td>00000M8Z.pdf.txt</td>\n",
       "      <td>302</td>\n",
       "      <td>The City will process payment within 60 days a...</td>\n",
       "      <td>[-0.107448906, -0.107014984, 0.010531411, -0.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680457</th>\n",
       "      <td>00000NB4.pdf.txt</td>\n",
       "      <td>332</td>\n",
       "      <td>INVOICES\\n\\n</td>\n",
       "      <td>[-0.69768953, 0.052773457, -0.34449014, -0.564...</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>False</td>\n",
       "      <td>0.969047</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235983</th>\n",
       "      <td>00000NHB.pdf.txt</td>\n",
       "      <td>309</td>\n",
       "      <td>The City will process payment within 60 days a...</td>\n",
       "      <td>[-0.12235852, -0.09604282, 0.036402386, -0.198...</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename  sentence_index  \\\n",
       "6454    00000JZM.pdf.txt             308   \n",
       "69340   00000LRJ.pdf.txt             294   \n",
       "445210  00000M8Z.pdf.txt             302   \n",
       "680457  00000NB4.pdf.txt             332   \n",
       "235983  00000NHB.pdf.txt             309   \n",
       "\n",
       "                                            sentence_text  \\\n",
       "6454    The City wil\\nprocess the payment within 60 ca...   \n",
       "69340   The City will process payment within 60 days a...   \n",
       "445210  The City will process payment within 60 days a...   \n",
       "680457                                       INVOICES\\n\\n   \n",
       "235983  The City will process payment within 60 days a...   \n",
       "\n",
       "                                                Embedding  Label Dataset  \\\n",
       "6454    [0.25620103, 0.11852089, -0.233818, -0.2146448...      1   Train   \n",
       "69340   [-0.12235852, -0.09604282, 0.036402386, -0.198...      1    Test   \n",
       "445210  [-0.107448906, -0.107014984, 0.010531411, -0.1...      1   Train   \n",
       "680457  [-0.69768953, 0.052773457, -0.34449014, -0.564...      0   Train   \n",
       "235983  [-0.12235852, -0.09604282, 0.036402386, -0.198...      1   Train   \n",
       "\n",
       "        Rule_Results  Probability  Predicted Label  \n",
       "6454            True     0.998688                1  \n",
       "69340           True     0.999777                1  \n",
       "445210          True     0.999809                1  \n",
       "680457         False     0.969047                1  \n",
       "235983          True     0.999777                1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_level_preds = ml_annotated_files.loc[ml_annotated_files.groupby('filename')[\"Probability\"].idxmax()]\n",
    "doc_level_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6986994b-c40d-4ebd-a5de-c6cdd7713615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  40]\n",
      " [  1 251]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        40\n",
      "           1       0.86      1.00      0.92       252\n",
      "\n",
      "    accuracy                           0.86       292\n",
      "   macro avg       0.43      0.50      0.46       292\n",
      "weighted avg       0.74      0.86      0.80       292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(doc_level_preds['Label'], doc_level_preds['Predicted Label']))\n",
    "print(classification_report(doc_level_preds['Label'], doc_level_preds['Predicted Label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce7951-76fd-4f20-9128-e1d81dce2d13",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Lucky for us, the top probability sentence for each document is also the annotated sentence in the majority of cases. An overall accuracy of 86% is pretty good to start, though we can make additional changes to the model and the data to continue to improve performance.\n",
    "\n",
    "*Note: Remember that in this case, by design when assessing our annotated documents, we expect each document to have a **true** prediction (e.g. no negative cases). We will cover confirming negative predictions momentarily in the next section.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ed8d0-1441-433d-8df6-5b0213826b3e",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.7:\n",
    "\n",
    "Split the document level metrics into the train and test set. How do the metrics compare at the document level for the training and testing sets?\n",
    "\n",
    "*Note that per best practices, we would typically look at both the sentence and document level training metrics as we iterate during development. Then, when ready, we would look at the sentence and document level metrics for the test set. The order is adjusted here for the sake of exercises.*\n",
    "\n",
    "<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd25fd-c635-4d9f-ad22-cd9db995e7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce4535-61bb-4c55-b921-1a8750000d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dc9b35b-8505-4d3e-a15f-0739fa8a8fb0",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.8:\n",
    "\n",
    "Explore the incorrect predictions in the training and testing sets. Are these bad annotations, or did the model predict incorrectly? If the former, what is the cause (e.g. multiple authoritative sources in the document)? If the latter, why do you think that may be?\n",
    "\n",
    "<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9089c54-d2bb-4695-b8ff-a9454a1fb958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb875fc6-40fe-475e-af93-61e3a2dda0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aede56db-4894-41c0-be2d-34c160332c59",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Next, there are a few additional steps we need to do to check and validate performance:\n",
    "1. Confirm performance on documents without any payment terms language\n",
    "2. Check performance on an out of sample set of annotations to confirm reasonable extrapolation of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b8e839-9747-4a47-9b0e-8a57bb8ba101",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "#### **Machine Learning**: Confirming Negative Predictions\n",
    "\n",
    "First, let's check performance on \"negative\" documents - cases where we know no payment terms language is present. We have provided a list of documents (via the Google drive) that do not have payment terms present, which we load below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "945281d6-c17c-459a-ab11-dc5838c302d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v5/zjyjffl52010h549863n0ggm0000gn/T/ipykernel_15220/1707978798.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ml_negs['Probability'] = ml_negs['Embedding'].apply(lambda x: clf.predict_proba([x])[0][1]);\n",
      "/var/folders/v5/zjyjffl52010h549863n0ggm0000gn/T/ipykernel_15220/1707978798.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ml_negs['Predicted Label'] = ml_negs['Probability'].apply(lambda x: 0 if x < threshold else 1);\n"
     ]
    }
   ],
   "source": [
    "neg_files = pd.read_excel(os.path.join(HOME_DIRECTORY, 'data', 'annotations', 'Payment_negative_docs.xlsx'))\n",
    "                 \n",
    "ml_negs = sentence_embeddings[sentence_embeddings['filename'].isin(neg_files['Filename'])]\n",
    "ml_negs['Probability'] = ml_negs['Embedding'].apply(lambda x: clf.predict_proba([x])[0][1]);\n",
    "ml_negs['Predicted Label'] = ml_negs['Probability'].apply(lambda x: 0 if x < threshold else 1);\n",
    "\n",
    "idx_max_prob_per_filename = ml_negs.groupby('filename')['Probability'].idxmax()\n",
    "top_rows_df = ml_negs.loc[idx_max_prob_per_filename]\n",
    "negs_doc_level_preds = top_rows_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac1f3e-ca26-4b77-bdf1-3af54aa5020a",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "Let's inspect the **false positive** predictions from these documents that do not have any payment terms language present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4533e0a0-a381-436c-a7fa-e6c3377ecd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Label</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Rule_Results</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00002V49.pdf.txt</td>\n",
       "      <td>22</td>\n",
       "      <td>The maximum compensation is increased from $30...</td>\n",
       "      <td>[0.060176883, 0.4465544, 0.12068288, -0.031842...</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>False</td>\n",
       "      <td>0.579256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>{526DE1DD-FAB2-44CA-BBD8-500AFB030E53}.pdf.txt</td>\n",
       "      <td>287</td>\n",
       "      <td>Programs are required to operate a minimum of ...</td>\n",
       "      <td>[0.62543714, -0.23115893, -0.17518792, -0.3102...</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>False</td>\n",
       "      <td>0.672136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>{FE20D4AB-BF71-4525-AE14-B5CE70748C8C}.pdf.txt</td>\n",
       "      <td>271</td>\n",
       "      <td>Programs are required to operate a minimum of ...</td>\n",
       "      <td>[0.46179008, -0.07574048, -0.059909284, -0.032...</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>False</td>\n",
       "      <td>0.731705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filename  sentence_index  \\\n",
       "17                                 00002V49.pdf.txt              22   \n",
       "86   {526DE1DD-FAB2-44CA-BBD8-500AFB030E53}.pdf.txt             287   \n",
       "105  {FE20D4AB-BF71-4525-AE14-B5CE70748C8C}.pdf.txt             271   \n",
       "\n",
       "                                         sentence_text  \\\n",
       "17   The maximum compensation is increased from $30...   \n",
       "86   Programs are required to operate a minimum of ...   \n",
       "105  Programs are required to operate a minimum of ...   \n",
       "\n",
       "                                             Embedding  Label Dataset  \\\n",
       "17   [0.060176883, 0.4465544, 0.12068288, -0.031842...      0   Train   \n",
       "86   [0.62543714, -0.23115893, -0.17518792, -0.3102...      0   Train   \n",
       "105  [0.46179008, -0.07574048, -0.059909284, -0.032...      0   Train   \n",
       "\n",
       "     Rule_Results  Probability  Predicted Label  \n",
       "17          False     0.579256                1  \n",
       "86          False     0.672136                1  \n",
       "105         False     0.731705                1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negs_doc_level_preds[negs_doc_level_preds['Predicted Label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5053df3e-d17e-4ee5-bc92-7775529e6637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The maximum compensation is increased from $30,000.00 to $40,000.00.',\n",
       "       'Programs are required to operate a minimum of 5 days and 30 hours\\n\\n',\n",
       "       'Programs are required to operate a minimum of $ days and 30 hours\\n\\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negs_doc_level_preds[negs_doc_level_preds['Predicted Label']==1]['sentence_text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e7957-90b4-4c07-82d4-a9312b16c322",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "We only have 3 false positives out of 107 documents - that's a pretty low false positive rate of <3%, which is pretty good. \n",
    "\n",
    "As we can see from inspecting the false positives:\n",
    "1. They are true false positives - it is always good to confirm we have not missed an annotation\n",
    "2. Most have relatively lower probabilities than the general population of predictions, in the 0.5 to 0.75 range.\n",
    "\n",
    "Although this is already quite good, how may we further improve these results? \n",
    "\n",
    "One option is to curate the negative examples we use in our machine learning model to allow the model to more clearly learn where the distinguishing line between the positive and negative classes lives. For example, we may run the model across a larger portion of the corpus to identify more cases where there is a false positive with high probability, and loop this back into training as negative examples.\n",
    "\n",
    "Another option is to check and assess the threshold between classes. For example, we may look at the distribution of model prediction probabilities for those classified both correctly and incorrectly, and assess if a change in the default threshold (p=0.5) would make sense to improve performance overall (or, more specifically, the metric we care most about)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f41d1b-56ff-4247-9991-1e134e20d701",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "#### **Machine Learning**: Full Document-Level Results\n",
    "\n",
    "Now, let's combine our doc-level results for both positive and negative classes --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96dac97c-54d9-455c-9e64-3fa569d79c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104  43]\n",
      " [  1 251]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.71      0.83       147\n",
      "           1       0.85      1.00      0.92       252\n",
      "\n",
      "    accuracy                           0.89       399\n",
      "   macro avg       0.92      0.85      0.87       399\n",
      "weighted avg       0.90      0.89      0.88       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_and_neg = pd.concat((doc_level_preds, negs_doc_level_preds))\n",
    "print(confusion_matrix(pos_and_neg['Label'], pos_and_neg['Predicted Label']))\n",
    "print(classification_report(pos_and_neg['Label'], pos_and_neg['Predicted Label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0b9638-c70b-44e6-8b98-be13924c4d09",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Overall, our results looking good! Let's move on to testing an out of sample set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123ea948-2cbf-4f42-ba3a-b17463881c7d",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "#### **Machine Learning**: Out of Sample Testing\n",
    "\n",
    "Now, let's test how well our machine learning models perform on a totally new set of data -- this is the same data we leveraged for out of sample testing for our rules (the CUAD dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0715c8af-fa7b-4fab-90d4-8da5ae7c7374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v5/zjyjffl52010h549863n0ggm0000gn/T/ipykernel_15220/1317929236.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ml_oob_annotated_files['Probability'] = ml_oob_annotated_files['Embedding'].apply(lambda x: clf.predict_proba([x])[0][1]);\n",
      "/var/folders/v5/zjyjffl52010h549863n0ggm0000gn/T/ipykernel_15220/1317929236.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ml_oob_annotated_files['Predicted Label'] = ml_oob_annotated_files['Probability'].apply(lambda x: 0 if x<threshold else 1);\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "ml_oob_annotated_files = OOS_sentences[OOS_sentences['filename'].isin(OOS_annos['Filename'])]\n",
    "ml_oob_annotated_files['Probability'] = ml_oob_annotated_files['Embedding'].apply(lambda x: clf.predict_proba([x])[0][1]);\n",
    "ml_oob_annotated_files['Predicted Label'] = ml_oob_annotated_files['Probability'].apply(lambda x: 0 if x<threshold else 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b4da818-e9cc-46c7-a32e-1dc0ac0a83a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 15]\n",
      " [ 1 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.76      0.98      0.86        49\n",
      "\n",
      "    accuracy                           0.75        64\n",
      "   macro avg       0.38      0.49      0.43        64\n",
      "weighted avg       0.58      0.75      0.66        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oob_doc_level_preds = ml_oob_annotated_files.loc[ml_oob_annotated_files.groupby('filename')[\"Probability\"].idxmax()]\n",
    "print(confusion_matrix(oob_doc_level_preds['Label'], oob_doc_level_preds['Predicted Label']))\n",
    "print(classification_report(oob_doc_level_preds['Label'], oob_doc_level_preds['Predicted Label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a4ce6-bf7d-4395-813a-681b64af80de",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "As expected, we see an overall performance drop when we run our model on the out of sample documents, down to overall 75% accuracy, largely due to false negative predictions.\n",
    "\n",
    "*Note: Again, remember that in this case, by design when assessing our annotated out-of-sample documents, we expect each document to have a true prediction (e.g. no negative cases). Exercise 6.11 covers including negative cases in the overall metrics.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff00447-1261-4aab-8069-d2332e995b07",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.9:\n",
    "\n",
    "Explore the false negatives - is there something unique about these examples that we are not capturing in our annotated dataset? If so, what are our next steps to improve the model's ability to extrapolate? (e.g. do we need to revisit our seeds for semantic search?) \n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1dfe52-d3e6-4ce2-88be-1c95759cf36c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe231e2-44cf-42b3-a995-4c68284872e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89f8c5b0-87bf-48cf-bba1-8c557c32f2fb",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.10:\n",
    "\n",
    "Find documents in our out of sample set that do not have payment terms language, and calculate a false positive rate. Combine the document-level metrics for positive and negative documents to calculate overall performance on the out-of-sample population.\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50cb79-9910-48a3-8635-8c5e2941d7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508e4d3f-a4d9-44b6-983d-20b3a4f2f462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0a7b930-5fe4-46de-8b35-dd5e2295eab2",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.11:\n",
    "\n",
    "Combine the regular expressions with the machine learning model. How does this impact performance overall on the train, test, and out-of-sample datasets?\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54647d30-c2cc-47b3-befa-7cebe5fdec04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16cb31-1245-46d5-b9c5-45cd96be08b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db87f00a-bd3c-43e3-8642-60ab1d999a40",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "#### **Machine Learning**: Comparative Performance of Random Annotations vs Targeted Annotations\n",
    "\n",
    "As discussed in the book, it's important to think critically about what data gets labeled for two purposes:\n",
    "1. Maximize the variability in the dataset to more quickly optimize model performance and generalizability\n",
    "2. Make the most of your subject matter experts' time in reviewing and labeling ground truth data\n",
    "\n",
    "Both these items are true regardless of the technical approach that is being adopted, and so it's worth taking a look at what happens when we don't think critically about our ground truth data. Here, we'll use a set of randomly selected dat that was annotated, and see how it impacts ML performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9dd4db6f-3aaa-41f2-bffc-80461d5ba58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d203747dex1015.html</td>\n",
       "      <td>6.3 Unless otherwise agreed in writing by\\nthe...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pinstripesdistributionag.html</td>\n",
       "      <td>The Customer agrees to pay such invoices withi...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spar ex99-1.htm</td>\n",
       "      <td>● All\\n                                       ...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a20240630ex103consultingag.html</td>\n",
       "      <td>Payment terms: net 30 days from receipt of inv...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbll-ex10_28.html</td>\n",
       "      <td>The Company will remit payment for properly su...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Filename  \\\n",
       "0              d203747dex1015.html   \n",
       "1    pinstripesdistributionag.html   \n",
       "2                  spar ex99-1.htm   \n",
       "3  a20240630ex103consultingag.html   \n",
       "4                cbll-ex10_28.html   \n",
       "\n",
       "                                                Text Answer  \n",
       "0  6.3 Unless otherwise agreed in writing by\\nthe...     30  \n",
       "1  The Customer agrees to pay such invoices withi...     30  \n",
       "2  ● All\\n                                       ...     30  \n",
       "3  Payment terms: net 30 days from receipt of inv...     30  \n",
       "4  The Company will remit payment for properly su...     30  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load randomly selected payment terms annotations\n",
    "payment_random_all = pd.read_excel(os.path.join(HOME_DIRECTORY, 'data', 'annotations', 'Payment_random_sample-annotated.xlsx'), engine='openpyxl')\n",
    "\n",
    "### Convert to embeddings\n",
    "payment_random_all['Embedding'] = payment_random_all['Text'].apply(lambda t: sent_emb_model.encode(t))\n",
    "\n",
    "### Remove false positives\n",
    "payment_random = payment_random_all[payment_random_all['Answer']!='FALSE POSITIVE']\n",
    "\n",
    "### Check\n",
    "payment_random[['Filename', 'Text', 'Answer']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdced556-06e6-4ae9-a16d-b49abcbd1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_annotated_files_random = sentence_embeddings[sentence_embeddings['filename'].isin(payment_random['Filename'])]\n",
    "ml_neg_sample_random = ml_annotated_files_random[ml_annotated_files_random['Label']==0].sample(n=5000, random_state=1)\n",
    "ml_pos_sample_random = ml_annotated_files_random[ml_annotated_files_random['Label']==1]\n",
    "ml_sample_random = pd.concat((ml_neg_sample_random, ml_pos_sample_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fc2890e-9d87-4efa-923c-77ba6ba25c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_random = []\n",
    "for x in ml_sample_random[ml_sample_random['Dataset']=='Train']['Embedding'].values:\n",
    "    X_train_random.append(x)\n",
    "\n",
    "X_test_random = []\n",
    "for x in ml_sample_random[ml_sample_random['Dataset']=='Test']['Embedding'].values:\n",
    "    X_test_random.append(x)\n",
    "\n",
    "y_train_random = ml_sample_random[ml_sample_random['Dataset']=='Train']['Label'].values\n",
    "y_test_random = ml_sample_random[ml_sample_random['Dataset']=='Test']['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19b9c549-a628-45e7-83a9-67c907a66827",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=150, random_state=1).fit(X_train_random, y_train_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f551f1ca-468a-444f-8562-699bc28ce48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4000    0]\n",
      " [   0   47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4000\n",
      "           1       1.00      1.00      1.00        47\n",
      "\n",
      "    accuracy                           1.00      4047\n",
      "   macro avg       1.00      1.00      1.00      4047\n",
      "weighted avg       1.00      1.00      1.00      4047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_random = clf.predict(X_train_random)\n",
    "print(confusion_matrix(y_train_random, y_pred_train_random))\n",
    "print(classification_report(y_train_random, y_pred_train_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "528066d2-8934-4112-a980-2dc19c27dcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[998   2]\n",
      " [  2   5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1000\n",
      "           1       0.71      0.71      0.71         7\n",
      "\n",
      "    accuracy                           1.00      1007\n",
      "   macro avg       0.86      0.86      0.86      1007\n",
      "weighted avg       1.00      1.00      1.00      1007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_random = clf.predict(X_test_random)\n",
    "print(confusion_matrix(y_test_random, y_pred_test_random))\n",
    "print(classification_report(y_test_random, clf.predict(X_test_random)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe73f7d9-cc82-4511-a414-efae5c36661f",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "As we can see, a randomly selected set looks to perform great on the training set, but fails to generalize nearly as well on the test set compared to our prior curated train and test datasets that were annotated. \n",
    "\n",
    "Because we have not thoughtfully ensured that our training and testing sets captures the variability of the underlying population, the model does not generalize as well.\n",
    "\n",
    "Even if we are not training a supervised model, it is still critical to ensure our curated datasets contain a wide swath of the variability in the corpus. If not, we will be developing rules or prompt engineering on a dataset that does not represent the variety of language we may see in the corpus. This is especially important if we have a corpus that has a big chunk of similar data but a long tail of variability.\n",
    "\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb967ea4-e822-4153-8fcc-b56342ef19a3",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.12:\n",
    "\n",
    "Test the model built on the random sample on the out-of-sample dataset. How do the OOS performances compare? Explain the reasons this may be the case.\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3be13a-cd79-4969-bd67-fe4651f71085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217f7a2-bda9-4d6c-939b-e3cbaea5365b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57cd7f19-ca68-488a-861f-a6d97f00ceee",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "# 3. GenAI RAG with LLM Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d66a8-11de-4046-a2b1-e23122ef0484",
   "metadata": {},
   "source": [
    "Now we move on to our final technique for this problem - leveraging semantic retrieval combined with a large language model to identify the correct context for payment terms.\n",
    "\n",
    "This requires two steps in our modeling process:\n",
    "1. Identify relevant payment terms candidates contexts based on semantic similarity\n",
    "2. Assess top candidates using LLM and return a well-structured response\n",
    "\n",
    "As part of step 2, we will need to do some iterative prompt engineering and assess against our training set to evaluate performance.\n",
    "\n",
    "**Note**: This section requires that the user set up an API key through OpenAI to use in the following code. We recommend starting with the OpenAI [quickstart guide](https://platform.openai.com/docs/quickstart) or the [API documentation](https://platform.openai.com/docs/api-reference/introduction). Once the key is set up, we recommend adding it to a .env file on your local instance of the repo. Alternatively, the user can set up an alternative LLM API and key, if preferred, and adjust the code in this section accordingly.\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8179e58-ec29-4a88-85db-f8b213043cf0",
   "metadata": {},
   "source": [
    "We'll load in an existing key that has been set up in the .env file, which we'll use for the below section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "701c8eba-404e-4c4c-be5c-79efecdc4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0890c1c-dbd8-49c7-8bea-0329924f0bc1",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Next, let's create a few functions that will let us create a prompt and send to the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6780466b-9c90-4171-b131-2cb37a0da1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_openai_request(prompt, openapi_key, model=\"gpt-5-mini-2025-08-07\", temperature=0.0, max_tokens=1000):\n",
    "  \"\"\"\n",
    "  Sends a request to the OpenAI API with the provided prompt and returns the response.\n",
    "\n",
    "  Args:\n",
    "      prompt: The text prompt to send to the OpenAI API.\n",
    "      openapi_key: API key set up to access OpenAI API.\n",
    "      model: The OpenAI model to use (default: \"gpt-5-mini-2025-08-07\").\n",
    "      temperature: Controls the randomness of the generated text (default: 0.0).\n",
    "      max_tokens: The maximum number of tokens to generate in the response (default: 1000).\n",
    "\n",
    "  Returns:\n",
    "      A dictionary containing the API response, including the generated text and other details.\n",
    "  \"\"\"  \n",
    "\n",
    "  try:\n",
    "    client = OpenAI(api_key = openapi_key)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        # temperature = temperature,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a legal expert doing your best to interpret text from a contract document.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "  except openai.error.OpenAIError as e:\n",
    "    raise Exception(f\"Error communicating with OpenAI API: {e}\")\n",
    "\n",
    "def construct_prompt(retrieved_sentences, indices):\n",
    "    'Uses pre-set instructions to embed the retrieved sentence and create a prompt for each API request and assesses the top 3 sentences only'\n",
    "    \n",
    "    prompt = '''You are a legal expert, doing your best to accurately interpret legal clauses and text. Your task is to interpret the language below to identify whether the text is \"Yes\" discussing payment terms or \"No\" discussing some other topic. Payment terms are the conditions set by businesses regarding when payments should be made for goods or services, specifically the number of days a buyer has to submit their payment. For example, \"Net 30\" means the buyer has 30 days to pay.\n",
    "\n",
    "Evaluate three sentences that are potentially relevant to payment terms. Assess which one is most likely referring to the payment terms and provide a response that gives the following information:\n",
    "    1. Context: the sentence that is most likely discussing payment terms from the examples; pick only one sentence and return as-is verbatim. If none, return \"Null\",\n",
    "    2. Index: the numerical, integer index that is associated to the context sentence, which is provided for each potential context\n",
    "    3. Payment Terms: an integer value indicating the number of days, e.g. \"30\" or \"60\". If payment terms is not an integer (such as \"as soon as possible\" or other non-integer value) return the relevant text. If none, return \"Null\"\n",
    "\n",
    "Provide your response in the specified json format below:\n",
    "    {'Context': <selected sentence most relevant to payment terms or Null>, \n",
    "    'Index': <index that corresponds to selected sentence>\n",
    "    'Payment Terms': <integer value or Null>}\n",
    "\n",
    "Examples to interpret: \n",
    "    1. Index = '''+str(indices[0])+''', \"''' + retrieved_sentences[0] + '''\"\n",
    "    2. Index = '''+str(indices[1])+''', \"''' + retrieved_sentences[1] + '''\"\n",
    "    3. Index = '''+str(indices[2])+''', \"''' + retrieved_sentences[2] + '''\"\n",
    "    '''\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c7076-09c9-4065-8772-776a520da28a",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "And now we'll test that with a dummy example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73df9b46-832d-4cde-98ee-fae71d78ea9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a legal expert, doing your best to accurately interpret legal clauses and text. Your task is to interpret the language below to identify whether the text is \"Yes\" discussing payment terms or \"No\" discussing some other topic. Payment terms are the conditions set by businesses regarding when payments should be made for goods or services, specifically the number of days a buyer has to submit their payment. For example, \"Net 30\" means the buyer has 30 days to pay.\n",
      "\n",
      "Evaluate three sentences that are potentially relevant to payment terms. Assess which one is most likely referring to the payment terms and provide a response that gives the following information:\n",
      "    1. Context: the sentence that is most likely discussing payment terms from the examples; pick only one sentence and return as-is verbatim. If none, return \"Null\",\n",
      "    2. Index: the numerical, integer index that is associated to the context sentence, which is provided for each potential context\n",
      "    3. Payment Terms: an integer value indicating the number of days, e.g. \"30\" or \"60\". If payment terms is not an integer (such as \"as soon as possible\" or other non-integer value) return the relevant text. If none, return \"Null\"\n",
      "\n",
      "Provide your response in the specified json format below:\n",
      "    {'Context': <selected sentence most relevant to payment terms or Null>, \n",
      "    'Index': <index that corresponds to selected sentence>\n",
      "    'Payment Terms': <integer value or Null>}\n",
      "\n",
      "Examples to interpret: \n",
      "    1. Index = 1234, \"Invoices must be sent to the mailing address above in order to be paid.\"\n",
      "    2. Index = 86754, \"The City will process invoices for payment within sixty days after receipt.\"\n",
      "    3. Index = 99876, \"Contractor will raise any issues or complaints about invoices within 90 days or be charged a late fee.\"\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "test_sentence = ['Invoices must be sent to the mailing address above in order to be paid.',\n",
    "                 'The City will process invoices for payment within sixty days after receipt.', \n",
    "                 'Contractor will raise any issues or complaints about invoices within 90 days or be charged a late fee.']\n",
    "\n",
    "prompt = construct_prompt(test_sentence, [1234, 86754, 99876])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e95b84aa-9fd6-4eed-8862-81bf62bf88e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{  \n",
      " \t\"Context\": \"The City will process invoices for payment within sixty days after receipt.\",  \n",
      " \t\"Index\": 86754,  \n",
      " \t\"Payment Terms\": 60  \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = send_openai_request(prompt, OPENAI_API_KEY)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c7ee7e-d989-4720-886b-843a1eb7c139",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "Now that we have the functionality set up for the prompt and LLM API call, let's also set up a semantic retrieval step. We'll set this up to pull the top three candidates from each document, and these three candidates will get automatically fed into the prompt for the LLM to assess.\n",
    "\n",
    "Passing the top three candidates is a strategic decision - we expect if we only use the top semantic search result, we will likely get more incorrect. By passing the additional candidates to the LLM, we expect to increase our overall performance by not relying solely on the retrieval step to get the correct context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42bce44f-99c5-40fd-a80c-2f99529ac648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_nn_for_examples(search_texts, u, sent_emb_model=sent_emb_model):\n",
    "    ranked_nn_array = []\n",
    "    example_embeds = []\n",
    "    for n, s in enumerate(search_texts):\n",
    "        emd_new = sent_emb_model.encode(s)\n",
    "        example_embeds.append(emd_new)\n",
    "        ranked_nn = u.get_nns_by_vector(emd_new, u.get_n_items())\n",
    "        ranked_nn_array.append(ranked_nn)\n",
    "    return ranked_nn_array, example_embeds\n",
    "\n",
    "def get_combined_sorted_nn(ranked_nn_array, file_indices, example_embeds, u):\n",
    "    df = pd.DataFrame()\n",
    "    for n, ranked_nn in enumerate(ranked_nn_array):\n",
    "        sorted_file_indices = []\n",
    "        sorted_distances = []\n",
    "        for i in ranked_nn: ## loop through entire list of sorted NN - repeated for each search example\n",
    "            if i in file_indices:\n",
    "                sorted_file_indices.append(i) ### in order of increasing distance from search\n",
    "                sorted_distances.append(math.dist(example_embeds[n], u.get_item_vector(i)))\n",
    "    \n",
    "        tmp = pd.DataFrame([[n]*len(sorted_file_indices), sorted_file_indices, sorted_distances]).T\n",
    "        df = pd.concat((df, tmp))\n",
    "    df.columns = ['Example ID', 'Index', 'Distance']\n",
    "    df = df.sort_values('Distance').drop_duplicates(subset=['Index'], keep='first')\n",
    "    return df\n",
    "\n",
    "def retrieve_sentences_per_doc(search_texts, annotated_files, annoy_database_filepath,\n",
    "                               embedding_model, top_n=3, vec_len=384):\n",
    "    u = AnnoyIndex(vec_len, 'angular')\n",
    "    u.load(annoy_database_filepath)\n",
    "\n",
    "    db_len = u.get_n_items()\n",
    "    ranked_nn_array, example_embeds = get_ranked_nn_for_examples(search_texts, u, sent_emb_model=embedding_model)\n",
    "\n",
    "    candidate_texts = []; candidate_indices = []\n",
    "    for f in annotated_files:\n",
    "        file_indices = sentence_embeddings[sentence_embeddings['filename'] == f].index.values\n",
    "        df = get_combined_sorted_nn(ranked_nn_array, file_indices, example_embeds, u)\n",
    "        candidate_text = [sentence_embeddings[sentence_embeddings.index==i]['sentence_text'].values[0] \n",
    "                           for i in df['Index'].values[:top_n]]\n",
    "        candidate_texts.append(candidate_text)\n",
    "        candidate_indices.append(df['Index'].values[:top_n])\n",
    "    return candidate_texts, candidate_indices\n",
    "\n",
    "def get_results_from_openai(annotated_files, candidate_texts, candidate_indices):\n",
    "    \"\"\"\n",
    "    Processes annotated files by sending prompts to the OpenAI API, handling JSON parsing errors.\n",
    "\n",
    "    Args:\n",
    "        annotated_files (list): List of filenames.\n",
    "        candidate_texts (list): List of text candidates.\n",
    "        candidate_indices (list): List of candidate indices.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the filename, prompt, and parsed API response.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for i, f in enumerate(annotated_files):\n",
    "        prompt = construct_prompt(candidate_texts[i], candidate_indices[i])\n",
    "        \n",
    "        # Initial attempt and retry loop for API call and JSON parsing\n",
    "        success = False\n",
    "        retry_count = 0\n",
    "        while not success and retry_count < 3:  # Retry up to 3 times\n",
    "            try:\n",
    "                response = send_openai_request(prompt, OPENAI_API_KEY)\n",
    "                data = json.loads(response)\n",
    "                context = data['Context']\n",
    "                sent_ind = data['Index']\n",
    "                terms = data['Payment Terms']\n",
    "                \n",
    "                tmp = pd.DataFrame([[f, prompt, sent_ind, context, terms]], \n",
    "                                   columns=['Filename', 'Prompt', 'Sent_Index', 'Context', 'Payment Terms'])\n",
    "                df = pd.concat((df, tmp))\n",
    "                success = True\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON decoding failed for file {f}: {e}. Retrying... (Attempt {retry_count + 1})\")\n",
    "                retry_count += 1\n",
    "                time.sleep(1) # Wait for 1 second before retrying\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred for file {f}: {e}.\")\n",
    "                break # Exit the retry loop for other types of errors\n",
    "        \n",
    "        if not success:\n",
    "            print(f\"Failed to process file {f} after multiple retries. Skipping...\")\n",
    "            # Optionally, log or handle the failure case here, e.g., by adding an empty row\n",
    "            # tmp = pd.DataFrame([[f, prompt, None, None, None]], \n",
    "            #                    columns=['Filename', 'Prompt', 'Sent_Index', 'Context', 'Payment Terms'])\n",
    "            # df = pd.concat((df, tmp))\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b371e548-08c0-4f1b-ba59-7a64e083173d",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "Now let's set up and run through our set of train and test documents with our GenAI RAG approach.\n",
    "\n",
    "*Note: For reference, at current token input and output costs for GPT-5 mini as of summer 2025, the cost to run through 280 documents is less than one dollar*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a50732a9-9b3e-48e8-9e4e-665ad070c7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Sent_Index</th>\n",
       "      <th>Context</th>\n",
       "      <th>Payment Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tm2421105d1_ex10-1.htm</td>\n",
       "      <td>You are a legal expert, doing your best to acc...</td>\n",
       "      <td>796139.0</td>\n",
       "      <td>Payment of invoices submitted for Services wil...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tm2022502d7_ex10-1.htm</td>\n",
       "      <td>You are a legal expert, doing your best to acc...</td>\n",
       "      <td>817242.0</td>\n",
       "      <td>Except as the applicable Provider and Recipien...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d203747dex1015.html</td>\n",
       "      <td>You are a legal expert, doing your best to acc...</td>\n",
       "      <td>902124.0</td>\n",
       "      <td>6.3 Unless otherwise agreed in writing by\\nthe...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pinstripesdistributionag.html</td>\n",
       "      <td>You are a legal expert, doing your best to acc...</td>\n",
       "      <td>856859.0</td>\n",
       "      <td>The Customer agrees to pay such invoices withi...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spar ex99-1.htm</td>\n",
       "      <td>You are a legal expert, doing your best to acc...</td>\n",
       "      <td>876506.0</td>\n",
       "      <td>● All\\n                                       ...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Filename  \\\n",
       "0         tm2421105d1_ex10-1.htm   \n",
       "1         tm2022502d7_ex10-1.htm   \n",
       "2            d203747dex1015.html   \n",
       "3  pinstripesdistributionag.html   \n",
       "4                spar ex99-1.htm   \n",
       "\n",
       "                                              Prompt  Sent_Index  \\\n",
       "0  You are a legal expert, doing your best to acc...    796139.0   \n",
       "1  You are a legal expert, doing your best to acc...    817242.0   \n",
       "2  You are a legal expert, doing your best to acc...    902124.0   \n",
       "3  You are a legal expert, doing your best to acc...    856859.0   \n",
       "4  You are a legal expert, doing your best to acc...    876506.0   \n",
       "\n",
       "                                             Context  Payment Terms  \n",
       "0  Payment of invoices submitted for Services wil...             30  \n",
       "1  Except as the applicable Provider and Recipien...             30  \n",
       "2  6.3 Unless otherwise agreed in writing by\\nthe...             30  \n",
       "3  The Customer agrees to pay such invoices withi...             30  \n",
       "4  ● All\\n                                       ...             30  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_search_texts = [\n",
    "    '''Invoices are to be submitted monthly in arrears, after services have been completed, to the address specified below. Payment\n",
    "    will be net thirty (30) days after receipt of an invoice in a format acceptable to Customer, as applicable.''',\n",
    "    '''Supplier agrees to pay customer the undisputed amount of an invoice within ninety (90) days after the date of a valid,\n",
    "    complete and properly documented invoice.''',\n",
    "    '''Unless otherwise noted, the buyer has sixty (60) days to pay invoice, as allowed by section 4.3.''',\n",
    "               ]\n",
    "annotated_filenames = payment_annos['Filename'].values\n",
    "annoy_database_filepath = os.path.join(HOME_DIRECTORY, 'data', 'annoy_indices', 'corpus_annoy_db.ann')\n",
    "\n",
    "candidate_texts, candidate_indices = retrieve_sentences_per_doc(payment_search_texts, annotated_filenames,\n",
    "                           annoy_database_filepath, sent_emb_model)\n",
    "results = get_results_from_openai(annotated_filenames, candidate_texts, candidate_indices)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16209e8-0383-4f3e-a326-abdaab046347",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "Now that we have our code set up, let's assess overall performance at the document level on the train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "02506723-68b8-4097-800c-753934cbb716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Index</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Text</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Sent_Index</th>\n",
       "      <th>Context</th>\n",
       "      <th>Payment Terms</th>\n",
       "      <th>GenAI_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tm2421105d1_ex10-1.htm</td>\n",
       "      <td>796139</td>\n",
       "      <td>0.826294</td>\n",
       "      <td>Payment of invoices submitted for Services wil...</td>\n",
       "      <td>[-0.11684367, -0.26367605, -0.073101826, -0.44...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "      <td>You are a legal expert, doing your best to acc...</td>\n",
       "      <td>796139.0</td>\n",
       "      <td>Payment of invoices submitted for Services wil...</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tm2022502d7_ex10-1.htm</td>\n",
       "      <td>817242</td>\n",
       "      <td>0.813836</td>\n",
       "      <td>Except as the applicable Provider and Recipien...</td>\n",
       "      <td>[-0.05047658, 0.05360353, -0.1944103, -0.06838...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "      <td>You are a legal expert, doing your best to acc...</td>\n",
       "      <td>817242.0</td>\n",
       "      <td>Except as the applicable Provider and Recipien...</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d203747dex1015.html</td>\n",
       "      <td>902124</td>\n",
       "      <td>0.801718</td>\n",
       "      <td>6.3 Unless otherwise agreed in writing by\\nthe...</td>\n",
       "      <td>[0.10877664, 0.02559523, -0.09234309, -0.09299...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "      <td>You are a legal expert, doing your best to acc...</td>\n",
       "      <td>902124.0</td>\n",
       "      <td>6.3 Unless otherwise agreed in writing by\\nthe...</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pinstripesdistributionag.html</td>\n",
       "      <td>856859</td>\n",
       "      <td>0.799900</td>\n",
       "      <td>The Customer agrees to pay such invoices withi...</td>\n",
       "      <td>[-0.06774448, -0.07578221, -0.23484963, -0.350...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "      <td>You are a legal expert, doing your best to acc...</td>\n",
       "      <td>856859.0</td>\n",
       "      <td>The Customer agrees to pay such invoices withi...</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spar ex99-1.htm</td>\n",
       "      <td>876506</td>\n",
       "      <td>0.797764</td>\n",
       "      <td>● All\\n                                       ...</td>\n",
       "      <td>[-0.17738397, -0.064912, 0.049998436, -0.23613...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "      <td>You are a legal expert, doing your best to acc...</td>\n",
       "      <td>876506.0</td>\n",
       "      <td>● All\\n                                       ...</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Filename   Index  Cosine Similarity  \\\n",
       "0         tm2421105d1_ex10-1.htm  796139           0.826294   \n",
       "1         tm2022502d7_ex10-1.htm  817242           0.813836   \n",
       "2            d203747dex1015.html  902124           0.801718   \n",
       "3  pinstripesdistributionag.html  856859           0.799900   \n",
       "4                spar ex99-1.htm  876506           0.797764   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Payment of invoices submitted for Services wil...   \n",
       "1  Except as the applicable Provider and Recipien...   \n",
       "2  6.3 Unless otherwise agreed in writing by\\nthe...   \n",
       "3  The Customer agrees to pay such invoices withi...   \n",
       "4  ● All\\n                                       ...   \n",
       "\n",
       "                                           Embedding Answer Comment Dataset  \\\n",
       "0  [-0.11684367, -0.26367605, -0.073101826, -0.44...     30     NaN   Train   \n",
       "1  [-0.05047658, 0.05360353, -0.1944103, -0.06838...     30     NaN    Test   \n",
       "2  [0.10877664, 0.02559523, -0.09234309, -0.09299...     30     NaN   Train   \n",
       "3  [-0.06774448, -0.07578221, -0.23484963, -0.350...     30     NaN    Test   \n",
       "4  [-0.17738397, -0.064912, 0.049998436, -0.23613...     30     NaN   Train   \n",
       "\n",
       "                                              Prompt Sent_Index  \\\n",
       "0  You are a legal expert, doing your best to acc...   796139.0   \n",
       "1  You are a legal expert, doing your best to acc...   817242.0   \n",
       "2  You are a legal expert, doing your best to acc...   902124.0   \n",
       "3  You are a legal expert, doing your best to acc...   856859.0   \n",
       "4  You are a legal expert, doing your best to acc...   876506.0   \n",
       "\n",
       "                                             Context Payment Terms  GenAI_Pred  \n",
       "0  Payment of invoices submitted for Services wil...            30        True  \n",
       "1  Except as the applicable Provider and Recipien...            30        True  \n",
       "2  6.3 Unless otherwise agreed in writing by\\nthe...            30        True  \n",
       "3  The Customer agrees to pay such invoices withi...            30        True  \n",
       "4  ● All\\n                                       ...            30        True  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genai_results = payment_annos.merge(results, left_on=['Filename', 'Index'], right_on=['Filename', 'Sent_Index'], how='left')\n",
    "\n",
    "## We'll add a column to indicate if we got the prediction correct based on sentence index\n",
    "genai_results['GenAI_Pred'] = genai_results['Index'] == genai_results['Sent_Index']\n",
    "\n",
    "genai_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f08fd-5283-4319-99f1-d0d7e171fcdb",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "Since these are all our positive annotations, let's do a quick check on accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "10dfd72a-4b70-446e-bc4e-6f3346f7c10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set # right: 174\n",
      "Train set # wrong: 60\n",
      "Train set accuracy: 74.4 %\n",
      "\n",
      "\n",
      "Test set # right: 42\n",
      "Test set # wrong: 16\n",
      "Test set accuracy: 72.4 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ds in ['Train', 'Test']:\n",
    "    print(ds, 'set # right:', \n",
    "          sum(genai_results[genai_results['Dataset']==ds]['GenAI_Pred']))\n",
    "    print(ds, 'set # wrong:', \n",
    "          len(genai_results[genai_results['Dataset']==ds]) - sum(genai_results[genai_results['Dataset']==ds]['GenAI_Pred']))\n",
    "    print(ds, 'set accuracy:', \n",
    "          round(100*(sum(genai_results[genai_results['Dataset']==ds]['GenAI_Pred'])/len(genai_results[genai_results['Dataset']==ds])), 1),'%')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb746f1-d7e8-4bed-a4db-53e61438dcfe",
   "metadata": {},
   "source": [
    "</br></br>\n",
    "\n",
    "In the remaining exercises for this section, we'll go through some of the same steps to assess and compare our results with a GenAI RAG approach to the other approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ece70e-dd5d-409d-8e00-8854af0fbc7b",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.13:\n",
    "\n",
    "Test this GenAI RAG approach on some of our negative document examples from the machine learning approach section. How well does the LLM perform on documents without payment term language, and can it properly differentiate between relevant and irrelevant context? Does the LLM have a bias towards non-null results?\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e1279-6ed2-4e17-8d5a-a9085737a9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e55ae-8e22-4fc7-bdc5-4d3c3345aa16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e0e959b-cad5-46aa-aab8-6f031a43c533",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.14:\n",
    "\n",
    "Try out some additional prompt engineering techniques. Are there methods you can take to improve overall performance?\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf2780-e298-40d0-9525-c66e407bd804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e296e-58e9-47dd-9d99-a95e296fb96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55bed550-18ec-4ff1-b3b6-624338d8a67d",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.15:\n",
    "\n",
    "Check the document-level performance on the out-of-sample annotations with our GenAI RAG approach. Is it comparable to our other approaches? \n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deaf7f8-cdf2-482a-b2df-4e7bba88ddfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64e7e1-34fb-474d-8974-e437ca74fe67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7575e3e7-f33c-4626-9090-c26c30308c40",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.16:\n",
    "\n",
    "- What is the document level performance for the parsing of the actual number of days (e.g. 30, 60) for this approach? \n",
    "- Does this \"compound\" model performance differ at all from the performance for retrieving and analyzing the correct sentence? \n",
    "- What does this indicate about the importance of these two separate pieces (retrieval vs understanding days) of the solution?\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2806d0ac-75b7-4eb1-988e-8cee95c8aed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd63af-9c7d-401a-9f8f-fc8fb1167e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ccdaf33-af50-4271-8858-069c105444a1",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.17:\n",
    "\n",
    "Explore the cases where the retrieval augmented generation approach was incorrect. Are these similar to the cases that the other approaches got incorrect? Why might that be? \n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012cdb9-8646-417e-87c0-01c508f401fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa946fb4-b38f-44d6-9ea9-fc49b6a70497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdebc028-b7f0-40c5-ac4f-cd9737c1932d",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.18:\n",
    "\n",
    "What happens if we test another LLM model instead? Are the results similar?\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2db860-8656-46e2-b21d-381a63176592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c36a72-4988-4a1b-b6d6-f93f1504f2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "846207f4-84cd-42f8-b833-c41252cb6d3e",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Exercise 6.19:\n",
    "\n",
    "Take the same three approaches for the limitation of liability field. How well does each of the three approaches work? What are some of the challenges with this field that are different from the payment terms field?\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0272a411-6f13-4e6f-86a0-23ebbf6098e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce67850-f41e-464a-ad3d-c16bcae4df0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c514f9fb-92e6-4b08-baa4-b278604028ca",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "# Next Steps\n",
    "\n",
    "While we have worked through many of the key components of data gathering, ingestion, pre-processing, exploration, dataset curation, and modeling, our journey is not yet done! \n",
    "\n",
    "Please continue to follow the [remaining steps and exercises](../) in the repo to complete the code companion with an end-to-end processing script, appropriate unit tests, documentation, model card, and more.\n",
    "\n",
    "<br/><br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tc2r_env",
   "language": "python",
   "name": "my_jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
